#!/usr/bin/env bash
set -euo pipefail

# --- Configuration ---
#MASTER_ADDR=${1:-"localhost"}
#MASTER_PORT=${2:-"29500"}
MASTER_ADDR="train-workers-0-0.train"
MASTER_PORT=3389
NODE_RANK="$NODE_RANK"
NUM_NODES="$NODE_COUNT"
NUM_GPU_PER_NODE=8
BATCH_SIZE_PER_GPU=${6:-"2"}
#ACCUMULATION_BATCH_SIZE=4
ACCUMULATION_STEPS=${7:-"4"}
NUM_CPU_CORES=8

# --- Paths ---
DATA_DIR="/gcs-dir/hf-data"
MODEL_PATH=$5  #"/gcs-dir/llama-7b"
OUTPUT_DIR="./results/llama-70b_scrolls_gov_report_r16_"
DEEPSPEED_CONFIG="ds_config.json"
HOSTFILE="hostfile"

# --- Setup ---
echo "Running on node rank $NODE_RANK of $NUM_NODES nodes with $NUM_GPU_PER_NODE GPUs."

# Set up NCCL environment variables

# Set up NCCL environment variables
source /usr/local/gib/scripts/set_nccl_env.sh

echo "$(cat /usr/local/gib/scripts/set_nccl_env.sh)"
#export NCCL_DEBUG=INFO
echo ""
echo "Environment variables set:"
echo "$(env)"
echo ""

# Write deepspeed env vars
cat <<EOT >~/.deepspeed_env
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
#export NCCL_DEBUG="INFO"
EOT

for line in $(env | grep NCCL)
do
    echo "export $line" >> ~/.deepspeed_env
done

echo "DeepSpeed environment variables:"
echo "$(cat ~/.deepspeed_env)"
echo ""

# Write deepspeed config
cat <<EOT >ds_config.json
{
 "fp16": {
 "enabled": false
 },
 "bf16": {
 "enabled": true
 },
 "optimizer": {
 "type": "Adam",
 "params": {
 "lr": "auto",
 "betas": [0.9, 0.999],
 "eps": 1e-8,
 "weight_decay": "auto",
 "torch_adam": true,
 "adam_w_mode": true
 }
 },
 "scheduler": {
 "type": "WarmupCosineLR",
 "params": {
 "total_num_steps": "auto",
 "warmup_min_ratio": 0.03,
 "warmup_num_steps": "auto"
 }
 },
  
"zero_optimization": {
 "stage": 3,
 "offload_optimizer": {
 "device": "none"
},
"offload_param": {
"device": "none"
},
 "overlap_comm": true,
 "contiguous_gradients": true,
 "sub_group_size": 1e9,
 "reduce_bucket_size": 3e9,
 "stage3_prefetch_bucket_size": 3e9,
 "stage3_param_persistence_threshold": 1e6,
 "stage3_max_live_parameters": 1.5e9,
 "stage3_max_reuse_distance": 1e9,
 "stage3_gather_16bit_weights_on_model_save": true,
 "memory_efficient_linear": true,
 "round_robin_gradients": true
 },
 "gradient_accumulation_steps": "auto",
 "gradient_clipping": "auto",
 "steps_per_print": 10,
 "train_batch_size": "auto",
 "train_micro_batch_size_per_gpu": "auto",
 "wall_clock_breakdown": false,
 "activation_checkpointing": {
 "partition_activations": true,
 "contiguous_memory_optimization": true,
 "number_checkpoints": 4
 }
}
EOT

# Write hostfile
cat <<EOT >hostfile
# This file is automatically generated by the training script.
# It contains the list of nodes and their ranks.
# Format: <node_name> slots=<num_slots>
$MASTER_ADDR slots=$NUM_GPU_PER_NODE
EOT

HOSTFILE="$(realpath hostfile)"
for ((i=1; i<NUM_NODES; i++)); do
    node_addr="$(echo $MASTER_ADDR | sed 's/0-0/0-'"${i}"'/g')"
    echo "$node_addr slots=$NUM_GPU_PER_NODE" >> "$HOSTFILE"
done


echo "Deepspeed hostfile:"
cat $HOSTFILE
echo ""

# Calculate gradient accumulation steps
#ACCUMULATION_STEPS=$((ACCUMULATION_BATCH_SIZE / (NUM_NODES * NUM_GPU_PER_NODE * BATCH_SIZE_PER_GPU)))

# --- Training ---
echo "Starting training..."

PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True" OMP_NUM_THREADS=$NUM_CPU_CORES deepspeed \
    --hostfile=$HOSTFILE \
    --no_ssh \
    --master_addr=$MASTER_ADDR \
    --master_port=$MASTER_PORT \
    --node_rank=$NODE_RANK \
    scripts/train.py \
    --dataset_path $DATA_DIR \
    --model_path $MODEL_PATH \
    --max_seq_len 8192 \
    --bf16 True \
    --logging_steps 24 \
    --eval_steps 48 \
    --output_dir $OUTPUT_DIR \
    --per_device_train_batch_size $BATCH_SIZE_PER_GPU \
    --gradient_accumulation_steps $ACCUMULATION_STEPS \
    --lr_scheduler_type cosine \
    --learning_rate 4e-4 \
    --weight_decay 0.0001 \
    --warmup_ratio 0 \
    --max_grad_norm 0.3 \
    --use_gradient_checkpointing True \
    --target_eval_loss 0.925 \
    --use_peft_lora True \
    --lora_r 16 \
    --lora_alpha 32 \
    --lora_dropout 0.1 \
    --max_steps 1024 \
    --use_flash_attn True \
    --seed 1234 \
    --lora_target_modules qkv_proj,o_proj \
    --deepspeed $DEEPSPEED_CONFIG

echo "Training completed."

                