+ echo 'Beginning trial 04 of 10'
Beginning trial 04 of 10
+ echo ':::DLPAL dockerd://mlperf-dell:bert 155 1 tnasnt6 '\''unknown'\'' XE9680Lx8B200-SXM-180GB_1x8x48x1_pack'
:::DLPAL dockerd://mlperf-dell:bert 155 1 tnasnt6 'unknown' XE9680Lx8B200-SXM-180GB_1x8x48x1_pack
++ srun -N1 -n1 --container-name=language_model_155 --no-container-mount-home --container-remap-root --container-writable mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.9 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"Dell B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch Dell Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-138-generic","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"INTEL(R) XEON(R) PLATINUM 8562Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.9 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"Dell B200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"183359 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch Dell Release 25.04","framework_name":"","other_software_stack":{"cuda_version":"12.9.0.036","cuda_driver_version":"575.51.02","nccl_version":"2.26.3","cublas_version":"12.9.0.2","cudnn_version":"9.9.0.52","trt_version":"10.9.0.34+cuda12.8","dali_version":"1.48.0","mofed_version":"5.4-rdmacore50.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-138-generic","nvidia_kernel_driver":"570.124.06"},"operating_system":"Ubuntu 24.04.2 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=language_model_155 --no-container-mount-home --container-remap-root --container-writable bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks-per-node=1 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on tnasnt6
vm.drop_caches = 3
+ srun --ntasks-per-node=1 --container-name=language_model_155 --no-container-mount-home --container-remap-root --container-writable python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746130488755, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746130489'
RUNANDTIME_START 1746130489
+ srun -l --mpi=none --ntasks-per-node=8 --time=12 --container-name=language_model_155 --no-container-mount-home --container-remap-root --container-writable --container-mounts=/training_datasets_v5.0/training_datasets_v4.1/bert/packed_data:/workspace/data_phase2,/training_datasets_v5.0/training_datasets_v4.1/bert/phase1:/workspace/phase1,/training_datasets_v5.0/training_datasets_v4.1/bert/hdf5/eval_varlength:/workspace/evaldata,/root/training_results_v5.0/bert/tunas_singlenode_results:/results --container-workdir=/workspace/bert --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
3: Run vars: id 155 gpus 8 mparams ''
2: Run vars: id 155 gpus 8 mparams ''
4: Run vars: id 155 gpus 8 mparams ''
5: Run vars: id 155 gpus 8 mparams ''
6: Run vars: id 155 gpus 8 mparams ''
7: Run vars: id 155 gpus 8 mparams ''
0: Run vars: id 155 gpus 8 mparams ''
1: Run vars: id 155 gpus 8 mparams ''
0: [W501 20:14:53.684639700 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: [W501 20:14:53.684638251 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [W501 20:14:53.684638635 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [W501 20:14:53.684644197 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: [W501 20:14:53.684638183 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
5: [W501 20:14:53.684638278 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
6: [W501 20:14:53.684642648 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: [W501 20:14:53.684640813 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
0:   warnings.warn(msg, DeprecatedFeatureWarning)
1: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
1:   warnings.warn(msg, DeprecatedFeatureWarning)
2: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
2:   warnings.warn(msg, DeprecatedFeatureWarning)
4: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
4:   warnings.warn(msg, DeprecatedFeatureWarning)
6: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
6:   warnings.warn(msg, DeprecatedFeatureWarning)
7: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
7:   warnings.warn(msg, DeprecatedFeatureWarning)
3: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
3:   warnings.warn(msg, DeprecatedFeatureWarning)
5: /usr/local/lib/python3.12/dist-packages/apex/__init__.py:67: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
5:   warnings.warn(msg, DeprecatedFeatureWarning)
4: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
4:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
6: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
6:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
7: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
7:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
6: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
6:   warnings.warn(msg)
7: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
7:   warnings.warn(msg)
4: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
4:   warnings.warn(msg)
6: [W501 20:15:05.461583436 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: [W501 20:15:05.461583348 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: [W501 20:15:05.461600032 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
4:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
6: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
6:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
7: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
7:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
6: :::MLLOG {"namespace": "", "time_ms": 1746130505954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
7: :::MLLOG {"namespace": "", "time_ms": 1746130505954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
4: :::MLLOG {"namespace": "", "time_ms": 1746130505954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
5: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
5:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
5: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
5:   warnings.warn(msg)
0: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
0:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
0: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
0:   warnings.warn(msg)
5: [W501 20:15:06.634605550 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [W501 20:15:06.635582852 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
5: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
5:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
0: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
0:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
5: :::MLLOG {"namespace": "", "time_ms": 1746130506127, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130506128, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
2: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
2:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
2: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
2:   warnings.warn(msg)
1: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
1:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
1: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
1:   warnings.warn(msg)
2: [W501 20:15:06.646876668 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: [W501 20:15:06.647742590 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
2:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
1: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
1:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
2: :::MLLOG {"namespace": "", "time_ms": 1746130506139, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
1: :::MLLOG {"namespace": "", "time_ms": 1746130506140, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
3: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception cannot import name 'MXFP8BlockScaling' from 'transformer_engine.common.recipe' (/usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py)
3:   warnings.warn(f"transformer_engine failed to import with exception {ex}")
3: /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.2.dev0-py3.12.egg/thunder/executors/transformer_engineex.py:62: UserWarning: Installed version of transformer_engine 1.11.0.dev0+98aa27a is not supported, please upgrade to version 2.0 from https://github.com/Dell/TransformerEngine/tree/release_v2.0. `transformer_engine_ex` will not be used.
3:   warnings.warn(msg)
3: [W501 20:15:06.695090544 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: /workspace/bert/run_pretraining.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
3:   grad_scaler = GradScaler(init_scale=float(os.getenv("INIT_LOSS_SCALE", 2**20)), growth_interval=2000)
3: :::MLLOG {"namespace": "", "time_ms": 1746130506187, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1390}}
4: [W501 20:15:09.637566782 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
7: [W501 20:15:09.637566726 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
4: device: cuda:4 n_gpu: 8, distributed training: True, 16-bits training: True
7: device: cuda:7 n_gpu: 8, distributed training: True, 16-bits training: True
5: [W501 20:15:09.638741208 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2: [W501 20:15:09.639340875 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
5: device: cuda:5 n_gpu: 8, distributed training: True, 16-bits training: True
2: device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
3: [W501 20:15:09.639665489 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
6: [W501 20:15:09.639850432 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
3: device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
6: device: cuda:6 n_gpu: 8, distributed training: True, 16-bits training: True
1: [W501 20:15:09.640390088 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
1: device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
0: [W501 20:15:09.641441753 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
0: device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xXE9680Lx8B200-SXM-180GB", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1397}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "seed", "value": 28255, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1399}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 768, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1401}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1403}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1405}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1407}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 3680.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1409}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130509131, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1411}}
0: parsed args:
0: Namespace(input_dir='/workspace/data_phase2', packed_samples=True, order_samples=False, max_pack_factor=3, average_packing_rate=2, synthetic_input=False, bert_model='bert-large-uncased', cuda_graph_mode='segmented', max_iterations_per_graph=4, output_dir='/results', eval_dir='/workspace/evaldata', eval_iter_start_samples=150000, eval_iter_samples=150000, num_eval_examples=10000, cache_eval_data=True, load_eval_synchronously=False, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, max_seq_length=512, max_predictions_per_seq=76, train_batch_size=48, eval_batch_size=16, learning_rate=0.00096, weight_decay_rate=0.1, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, max_steps=3680.0, sustained_training_time=0, max_samples_termination=4500000.0, warmup_proportion=0.0, warmup_steps=0.0, start_warmup_step=0.0, local_rank=0, seed=28255, gradient_accumulation_steps=1, fp16=True, loss_scale=0.0, log_freq=0.0, checkpoint_activations=False, resume_from_checkpoint=False, keep_n_most_recent_c
0: heckpoints=20, num_samples_per_checkpoint=500000, min_samples_to_start_checkpoints=3000000, skip_checkpoint=True, phase2=True, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, do_train=True, exchange_padding=False, unpad=False, unpad_fmha=False, pad_fmha=True, pad=False, enable_fuse_dropout=False, disable_fuse_mask=False, disable_fuse_scale=False, disable_fuse_qkv=False, disable_apex_softmax=False, enable_stream=False, fused_gemm_gelu=True, fused_mha=False, fused_gelu_bias=False, fused_dropout_add=True, fused_bias_mha=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, dense_seq_output=True, use_env=False, bert_config_path='/workspace/phase1/bert_config.json', target_mlm_accuracy=0.72, train_mlm_accuracy_window_size=0, num_epochs_to_generate_seeds_for=2, use_cuda_graph=True, eval_cuda_graph=True, use_ddp=False, ddp_type='apex', use_gradient_as_bucket_view=False, bypass_amp=False, distributed_lamb=True, dwu_group_size=0, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_nu
0: m_ar_pg=1, dwu_num_ag_pg=1, dwu_overlap_reductions=False, dwu_e5m2_allgather=False, use_transformer_engine=False, use_transformer_engine2=True, n_gpu=8, device=device(type='cuda', index=0))
4: Torch distributed is available.
4: Torch distributed is initialized.
7: Torch distributed is available.
7: Torch distributed is initialized.
6: Torch distributed is available.
6: Torch distributed is initialized.
5: Torch distributed is available.
5: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
3: Torch distributed is available.
3: Torch distributed is initialized.
2: Torch distributed is available.
2: Torch distributed is initialized.
0: Torch distributed is available.
0: Torch distributed is initialized.
0: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
0:   warnings.warn(
2: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
2:   warnings.warn(
3: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
3:   warnings.warn(
1: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
1:   warnings.warn(
4: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
4:   warnings.warn(
5: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
5:   warnings.warn(
6: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
6:   warnings.warn(
7: /usr/local/lib/python3.12/dist-packages/transformer_engine/common/recipe/__init__.py:153: DeprecationWarning: `interval` argument is deprecated and unused. It will be removed in an upcoming release.
7:   warnings.warn(
0: :::MLLOG {"namespace": "", "time_ms": 1746130513716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/word_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/position_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/token_type_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/embeddings/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
6: BertForPreTrainingSegmented(
6:   (bert_model_segment): BertForPreTrainingModelOnly(
6:     (bert): BertModel(
6:       (embeddings): BertEmbeddings(
6:         (word_embeddings): Embedding(30528, 1024)
6:         (position_embeddings): Embedding(512, 1024)
6:         (token_type_embeddings): Embedding(2, 1024)
6:         (LayerNorm): FastLayerNorm()
6:         (dropout): Dropout(p=0.1, inplace=False)
6:       )
6:       (encoder): BertEncoder(
6:         (layer): ModuleList(
6:           (0-23): 24 x BertTransformerLayer2(
6:             (attention): FP8_MHA()
6:             (layernorm_mlp): LayerNormMLP()
6:             (output_LayerNorm): FastLayerNorm()
6:           )
6:         )
6:       )
6:       (pooler): BertPooler(
6:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
6:         (activation): Tanh()
6:       )
6:     )
6:   )
6:   (heads_only_segment): BertForPreTrainingHeadsOnly(
6:     (cls): BertPreTrainingHeads(
6:       (predictions): BertLMPredictionHead(
6:         (transform): BertPredictionHeadTransform(
6:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
6:           (LayerNorm): FastLayerNorm()
6:         )
6:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
6:       )
6:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
6:     )
6:   )
6: )
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
2: BertForPreTrainingSegmented(
2:   (bert_model_segment): BertForPreTrainingModelOnly(
2:     (bert): BertModel(
2:       (embeddings): BertEmbeddings(
2:         (word_embeddings): Embedding(30528, 1024)
2:         (position_embeddings): Embedding(512, 1024)
2:         (token_type_embeddings): Embedding(2, 1024)
2:         (LayerNorm): FastLayerNorm()
2:         (dropout): Dropout(p=0.1, inplace=False)
2:       )
2:       (encoder): BertEncoder(
2:         (layer): ModuleList(
2:           (0-23): 24 x BertTransformerLayer2(
2:             (attention): FP8_MHA()
2:             (layernorm_mlp): LayerNormMLP()
2:             (output_LayerNorm): FastLayerNorm()
2:           )
2:         )
2:       )
2:       (pooler): BertPooler(
2:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
2:         (activation): Tanh()
2:       )
2:     )
2:   )
2:   (heads_only_segment): BertForPreTrainingHeadsOnly(
2:     (cls): BertPreTrainingHeads(
2:       (predictions): BertLMPredictionHead(
2:         (transform): BertPredictionHeadTransform(
2:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
2:           (LayerNorm): FastLayerNorm()
2:         )
2:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
2:       )
2:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
2:     )
2:   )
2: )
3: BertForPreTrainingSegmented(
3:   (bert_model_segment): BertForPreTrainingModelOnly(
3:     (bert): BertModel(
3:       (embeddings): BertEmbeddings(
3:         (word_embeddings): Embedding(30528, 1024)
3:         (position_embeddings): Embedding(512, 1024)
3:         (token_type_embeddings): Embedding(2, 1024)
3:         (LayerNorm): FastLayerNorm()
3:         (dropout): Dropout(p=0.1, inplace=False)
3:       )
3:       (encoder): BertEncoder(
3:         (layer): ModuleList(
3:           (0-23): 24 x BertTransformerLayer2(
3:             (attention): FP8_MHA()
3:             (layernorm_mlp): LayerNormMLP()
3:             (output_LayerNorm): FastLayerNorm()
3:           )
3:         )
3:       )
3:       (pooler): BertPooler(
3:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
3:         (activation): Tanh()
3:       )
3:     )
3:   )
3:   (heads_only_segment): BertForPreTrainingHeadsOnly(
3:     (cls): BertPreTrainingHeads(
3:       (predictions): BertLMPredictionHead(
3:         (transform): BertPredictionHeadTransform(
3:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
3:           (LayerNorm): FastLayerNorm()
3:         )
3:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
3:       )
3:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
3:     )
3:   )
3: )
1: BertForPreTrainingSegmented(
1:   (bert_model_segment): BertForPreTrainingModelOnly(
1:     (bert): BertModel(
1:       (embeddings): BertEmbeddings(
1:         (word_embeddings): Embedding(30528, 1024)
1:         (position_embeddings): Embedding(512, 1024)
1:         (token_type_embeddings): Embedding(2, 1024)
1:         (LayerNorm): FastLayerNorm()
1:         (dropout): Dropout(p=0.1, inplace=False)
1:       )
1:       (encoder): BertEncoder(
1:         (layer): ModuleList(
1:           (0-23): 24 x BertTransformerLayer2(
1:             (attention): FP8_MHA()
1:             (layernorm_mlp): LayerNormMLP()
1:             (output_LayerNorm): FastLayerNorm()
1:           )
1:         )
1:       )
1:       (pooler): BertPooler(
1:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
1:         (activation): Tanh()
1:       )
1:     )
1:   )
1:   (heads_only_segment): BertForPreTrainingHeadsOnly(
1:     (cls): BertPreTrainingHeads(
1:       (predictions): BertLMPredictionHead(
1:         (transform): BertPredictionHeadTransform(
1:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
1:           (LayerNorm): FastLayerNorm()
1:         )
1:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
1:       )
1:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
1:     )
1:   )
1: )
5: BertForPreTrainingSegmented(
5:   (bert_model_segment): BertForPreTrainingModelOnly(
5:     (bert): BertModel(
5:       (embeddings): BertEmbeddings(
5:         (word_embeddings): Embedding(30528, 1024)
5:         (position_embeddings): Embedding(512, 1024)
5:         (token_type_embeddings): Embedding(2, 1024)
5:         (LayerNorm): FastLayerNorm()
5:         (dropout): Dropout(p=0.1, inplace=False)
5:       )
5:       (encoder): BertEncoder(
5:         (layer): ModuleList(
5:           (0-23): 24 x BertTransformerLayer2(
5:             (attention): FP8_MHA()
5:             (layernorm_mlp): LayerNormMLP()
5:             (output_LayerNorm): FastLayerNorm()
5:           )
5:         )
5:       )
5:       (pooler): BertPooler(
5:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
5:         (activation): Tanh()
5:       )
5:     )
5:   )
5:   (heads_only_segment): BertForPreTrainingHeadsOnly(
5:     (cls): BertPreTrainingHeads(
5:       (predictions): BertLMPredictionHead(
5:         (transform): BertPredictionHeadTransform(
5:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
5:           (LayerNorm): FastLayerNorm()
5:         )
5:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
5:       )
5:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
5:     )
5:   )
5: )
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
4: BertForPreTrainingSegmented(
4:   (bert_model_segment): BertForPreTrainingModelOnly(
4:     (bert): BertModel(
4:       (embeddings): BertEmbeddings(
4:         (word_embeddings): Embedding(30528, 1024)
4:         (position_embeddings): Embedding(512, 1024)
4:         (token_type_embeddings): Embedding(2, 1024)
4:         (LayerNorm): FastLayerNorm()
4:         (dropout): Dropout(p=0.1, inplace=False)
4:       )
4:       (encoder): BertEncoder(
4:         (layer): ModuleList(
4:           (0-23): 24 x BertTransformerLayer2(
4:             (attention): FP8_MHA()
4:             (layernorm_mlp): LayerNormMLP()
4:             (output_LayerNorm): FastLayerNorm()
4:           )
4:         )
4:       )
4:       (pooler): BertPooler(
4:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
4:         (activation): Tanh()
4:       )
4:     )
4:   )
4:   (heads_only_segment): BertForPreTrainingHeadsOnly(
4:     (cls): BertPreTrainingHeads(
4:       (predictions): BertLMPredictionHead(
4:         (transform): BertPredictionHeadTransform(
4:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
4:           (LayerNorm): FastLayerNorm()
4:         )
4:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
4:       )
4:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
4:     )
4:   )
4: )
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
7: BertForPreTrainingSegmented(
7:   (bert_model_segment): BertForPreTrainingModelOnly(
7:     (bert): BertModel(
7:       (embeddings): BertEmbeddings(
7:         (word_embeddings): Embedding(30528, 1024)
7:         (position_embeddings): Embedding(512, 1024)
7:         (token_type_embeddings): Embedding(2, 1024)
7:         (LayerNorm): FastLayerNorm()
7:         (dropout): Dropout(p=0.1, inplace=False)
7:       )
7:       (encoder): BertEncoder(
7:         (layer): ModuleList(
7:           (0-23): 24 x BertTransformerLayer2(
7:             (attention): FP8_MHA()
7:             (layernorm_mlp): LayerNormMLP()
7:             (output_LayerNorm): FastLayerNorm()
7:           )
7:         )
7:       )
7:       (pooler): BertPooler(
7:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
7:         (activation): Tanh()
7:       )
7:     )
7:   )
7:   (heads_only_segment): BertForPreTrainingHeadsOnly(
7:     (cls): BertPreTrainingHeads(
7:       (predictions): BertLMPredictionHead(
7:         (transform): BertPredictionHeadTransform(
7:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
7:           (LayerNorm): FastLayerNorm()
7:         )
7:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
7:       )
7:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
7:     )
7:   )
7: )
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513728, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513729, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513741, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513742, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513746, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513751, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/pooler/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "bert/pooler/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/output_bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/seq_relationship/output_weights"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130513754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 954, "tensor": "cls/seq_relationship/output_bias"}}
0: BertForPreTrainingSegmented(
0:   (bert_model_segment): BertForPreTrainingModelOnly(
0:     (bert): BertModel(
0:       (embeddings): BertEmbeddings(
0:         (word_embeddings): Embedding(30528, 1024)
0:         (position_embeddings): Embedding(512, 1024)
0:         (token_type_embeddings): Embedding(2, 1024)
0:         (LayerNorm): FastLayerNorm()
0:         (dropout): Dropout(p=0.1, inplace=False)
0:       )
0:       (encoder): BertEncoder(
0:         (layer): ModuleList(
0:           (0-23): 24 x BertTransformerLayer2(
0:             (attention): FP8_MHA()
0:             (layernorm_mlp): LayerNormMLP()
0:             (output_LayerNorm): FastLayerNorm()
0:           )
0:         )
0:       )
0:       (pooler): BertPooler(
0:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
0:         (activation): Tanh()
0:       )
0:     )
0:   )
0:   (heads_only_segment): BertForPreTrainingHeadsOnly(
0:     (cls): BertPreTrainingHeads(
0:       (predictions): BertLMPredictionHead(
0:         (transform): BertPredictionHeadTransform(
0:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
0:           (LayerNorm): FastLayerNorm()
0:         )
0:         (decoder): Linear(in_features=1024, out_features=30528, bias=False)
0:       )
0:       (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)
0:     )
0:   )
0: )
2: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
2:   self._overflow_buf = torch.cuda.IntTensor([0])
2: [rank2]:[W501 20:15:13.440056712 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1746130513962, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00096, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 991}}
0: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
0:   self._overflow_buf = torch.cuda.IntTensor([0])
0: [rank0]:[W501 20:15:13.476223037 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
6: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
6:   self._overflow_buf = torch.cuda.IntTensor([0])
6: [rank6]:[W501 20:15:13.489278806 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 6]  using GPU 6 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
1: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
1:   self._overflow_buf = torch.cuda.IntTensor([0])
3: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
3:   self._overflow_buf = torch.cuda.IntTensor([0])
7: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
7:   self._overflow_buf = torch.cuda.IntTensor([0])
1: [rank1]:[W501 20:15:13.490805890 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
5: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
5:   self._overflow_buf = torch.cuda.IntTensor([0])
3: [rank3]:[W501 20:15:13.491457289 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
7: [rank7]:[W501 20:15:13.491884161 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 7]  using GPU 7 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
4: /usr/local/lib/python3.12/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py:119: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
4:   self._overflow_buf = torch.cuda.IntTensor([0])
5: [rank5]:[W501 20:15:13.492227917 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 5]  using GPU 5 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
4: [rank4]:[W501 20:15:13.492928463 ProcessGroupNCCL.cpp:4751] [PG ID 3 PG GUID 3 Rank 4]  using GPU 4 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
0: :::MLLOG {"namespace": "", "time_ms": 1746130515644, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1030}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515645, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1031}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515645, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.60466, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1033}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515645, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.85437, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1034}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515645, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1035}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515700, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515700, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130515701, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
0: Torch distributed is available.
0: Torch distributed is initialized.
2: Torch distributed is available.
2: Torch distributed is initialized.
3: Torch distributed is available.
3: Torch distributed is initialized.
5: Torch distributed is available.
5: Torch distributed is initialized.
6: Torch distributed is available.
6: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
4: Torch distributed is available.
4: Torch distributed is initialized.
7: Torch distributed is available.
7: Torch distributed is initialized.
2: Enabling make_graphed_callables for encoder!!
6: Enabling make_graphed_callables for encoder!!
5: Enabling make_graphed_callables for encoder!!
0: Enabling make_graphed_callables for encoder!!
3: Enabling make_graphed_callables for encoder!!
4: Enabling make_graphed_callables for encoder!!
1: Enabling make_graphed_callables for encoder!!
7: Enabling make_graphed_callables for encoder!!
1: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
4: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
6: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
7: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
0: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
3: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
5: /usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
2:   warnings.warn(
0: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
0:   warnings.warn(
1: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
1:   warnings.warn(
4: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
4:   warnings.warn(
3: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
3:   warnings.warn(
6: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
6:   warnings.warn(
7: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
7:   warnings.warn(
5: /usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py:419: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
5:   warnings.warn(
0: :::MLLOG {"namespace": "", "time_ms": 1746130520675, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1783}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130520675, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1783}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130520695, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1805, "epoch_num": 0}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130520696, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1807, "first_epoch_num": 1, "epoch_count": 1}}
0: parsed args:
0: Namespace(input_dir='/workspace/data_phase2', packed_samples=True, order_samples=False, max_pack_factor=3, average_packing_rate=2, synthetic_input=False, bert_model='bert-large-uncased', cuda_graph_mode='segmented', max_iterations_per_graph=4, output_dir='/results', eval_dir='/workspace/evaldata', eval_iter_start_samples=150000, eval_iter_samples=150000, num_eval_examples=10000, cache_eval_data=True, load_eval_synchronously=False, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, max_seq_length=512, max_predictions_per_seq=76, train_batch_size=48, eval_batch_size=16, learning_rate=0.00096, weight_decay_rate=0.1, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, max_steps=3680.0, sustained_training_time=0, max_samples_termination=4500000.0, warmup_proportion=0.0, warmup_steps=0.0, start_warmup_step=0.0, local_rank=0, seed=28255, gradient_accumulation_steps=1, fp16=True, loss_scale=0.0, log_freq=0.0, checkpoint_activations=False, resume_from_checkpoint=False, keep_n_most_recent_c
0: heckpoints=20, num_samples_per_checkpoint=500000, min_samples_to_start_checkpoints=3000000, skip_checkpoint=True, phase2=True, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, do_train=True, exchange_padding=False, unpad=False, unpad_fmha=False, pad_fmha=True, pad=False, enable_fuse_dropout=False, disable_fuse_mask=False, disable_fuse_scale=False, disable_fuse_qkv=False, disable_apex_softmax=False, enable_stream=False, fused_gemm_gelu=True, fused_mha=False, fused_gelu_bias=False, fused_dropout_add=True, fused_bias_mha=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, dense_seq_output=True, use_env=False, bert_config_path='/workspace/phase1/bert_config.json', target_mlm_accuracy=0.72, train_mlm_accuracy_window_size=0, num_epochs_to_generate_seeds_for=2, use_cuda_graph=True, eval_cuda_graph=True, use_ddp=False, ddp_type='apex', use_gradient_as_bucket_view=False, bypass_amp=False, distributed_lamb=True, dwu_group_size=0, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_nu
0: m_ar_pg=1, dwu_num_ag_pg=1, dwu_overlap_reductions=False, dwu_e5m2_allgather=False, use_transformer_engine=False, use_transformer_engine2=True, n_gpu=8, device=device(type='cuda', index=0), resume_step=0)
0: epoch: 1
0: :::MLLOG {"namespace": "", "time_ms": 1746130520697, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_01108", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1844}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130533287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11917.518977581547}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 150039}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130533288, "event_type": "INTERVAL_START", "key": "eval_start", "value": 150039, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 150039}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130534214, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 150039, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 150039}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130534215, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3789578080177307, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 150039}}
0: {'global_steps': 196, 'eval_loss': 4.061295986175537, 'eval_mlm_accuracy': 0.3789578080177307}
0: :::MLLOG {"namespace": "", "time_ms": 1746130546431, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11409.066018575013}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 299999}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130546432, "event_type": "INTERVAL_START", "key": "eval_start", "value": 299999, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 299999}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130547016, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 299999, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 299999}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130547017, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4037269353866577, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 299999}}
0: {'global_steps': 391, 'eval_loss': 3.8326053619384766, 'eval_mlm_accuracy': 0.4037269353866577}
0: :::MLLOG {"namespace": "", "time_ms": 1746130558813, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12104.336565895464}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 449884}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130558815, "event_type": "INTERVAL_START", "key": "eval_start", "value": 449884, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 449884}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130559401, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 449884, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 449884}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130559402, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.47233644127845764, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 449884}}
0: {'global_steps': 586, 'eval_loss': 3.2280757427215576, 'eval_mlm_accuracy': 0.47233644127845764}
0: :::MLLOG {"namespace": "", "time_ms": 1746130571727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11640.2741335732}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 600201}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130571729, "event_type": "INTERVAL_START", "key": "eval_start", "value": 600201, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 600201}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130572314, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 600201, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 600201}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130572315, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6030870676040649, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 600201}}
0: {'global_steps': 782, 'eval_loss': 2.1351113319396973, 'eval_mlm_accuracy': 0.6030870676040649}
0: :::MLLOG {"namespace": "", "time_ms": 1746130584124, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12076.577592866983}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 749910}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130584125, "event_type": "INTERVAL_START", "key": "eval_start", "value": 749910, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 749910}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130584710, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 749910, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 749910}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130584711, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6947774291038513, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 749910}}
0: {'global_steps': 977, 'eval_loss': 1.4656907320022583, 'eval_mlm_accuracy': 0.6947774291038513}
0: :::MLLOG {"namespace": "", "time_ms": 1746130597240, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11400.180721179684}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 899444}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130597242, "event_type": "INTERVAL_START", "key": "eval_start", "value": 899444, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 899444}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130597830, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 899444, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 899444}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130597831, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7057830691337585, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 899444}}
0: {'global_steps': 1172, 'eval_loss': 1.3916590213775635, 'eval_mlm_accuracy': 0.7057830691337585}
0: :::MLLOG {"namespace": "", "time_ms": 1746130610220, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11548.514233550255}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1049336}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130610221, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1049336, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1049336}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130610804, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1049336, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1049336}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130610805, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7102338671684265, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1049336}}
0: {'global_steps': 1368, 'eval_loss': 1.3653569221496582, 'eval_mlm_accuracy': 0.7102338671684265}
0: :::MLLOG {"namespace": "", "time_ms": 1746130623142, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11589.151060240043}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1199099}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130623144, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1199099, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1199099}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130623729, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1199099, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1199099}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130623730, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7119408845901489, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1199099}}
0: {'global_steps': 1563, 'eval_loss': 1.3545085191726685, 'eval_mlm_accuracy': 0.7119408845901489}
0: :::MLLOG {"namespace": "", "time_ms": 1746130635562, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12071.560982727327}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1349029}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130635563, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1349029, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1349029}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130636149, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1349029, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1349029}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130636150, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7140775322914124, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1349029}}
0: {'global_steps': 1758, 'eval_loss': 1.3427832126617432, 'eval_mlm_accuracy': 0.7140775322914124}
0: :::MLLOG {"namespace": "", "time_ms": 1746130648628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11495.288020760843}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1499218}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130648629, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1499218, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1499218}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130649215, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1499218, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1499218}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130649216, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7155043482780457, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1499218}}
0: {'global_steps': 1954, 'eval_loss': 1.335373044013977, 'eval_mlm_accuracy': 0.7155043482780457}
0: :::MLLOG {"namespace": "", "time_ms": 1746130661035, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12048.2543901485}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1648702}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130661036, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1648702, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1648702}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130661621, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1648702, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1648702}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130661622, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7162165641784668, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1648702}}
0: {'global_steps': 2149, 'eval_loss': 1.33057701587677, 'eval_mlm_accuracy': 0.7162165641784668}
0: :::MLLOG {"namespace": "", "time_ms": 1746130673978, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11579.580836486122}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1798575}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130673979, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1798575, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1798575}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130674564, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1798575, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1798575}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130674565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.716905415058136, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1798575}}
0: {'global_steps': 2344, 'eval_loss': 1.3235889673233032, 'eval_mlm_accuracy': 0.716905415058136}
0: :::MLLOG {"namespace": "", "time_ms": 1746130686461, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12060.824185355581}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 1949128}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130686462, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1949128, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 1949128}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130687046, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1949128, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 1949128}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130687047, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7180940508842468, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 1949128}}
0: {'global_steps': 2540, 'eval_loss': 1.319064974784851, 'eval_mlm_accuracy': 0.7180940508842468}
0: :::MLLOG {"namespace": "", "time_ms": 1746130699351, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11615.203093009015}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2098856}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130699352, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2098856, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2098856}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130699938, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2098856, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2098856}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130699939, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7184582948684692, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2098856}}
0: {'global_steps': 2735, 'eval_loss': 1.316422939300537, 'eval_mlm_accuracy': 0.7184582948684692}
0: :::MLLOG {"namespace": "", "time_ms": 1746130711764, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12061.637888806561}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2248569}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130711765, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2248569, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2248569}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130712352, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2248569, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2248569}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130712353, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7191915512084961, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2248569}}
0: {'global_steps': 2930, 'eval_loss': 1.3124418258666992, 'eval_mlm_accuracy': 0.7191915512084961}
0: :::MLLOG {"namespace": "", "time_ms": 1746130724696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11571.76962851949}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2398217}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130724697, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2398217, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2398217}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130725284, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2398217, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2398217}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130725285, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7198360562324524, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2398217}}
0: {'global_steps': 3125, 'eval_loss': 1.3094638586044312, 'eval_mlm_accuracy': 0.7198360562324524}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 12094.251456790395}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2019, "epoch_num": 2549165}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737178, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2549165, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2025, "epoch_num": 2549165}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737762, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2549165, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2034, "epoch_num": 2549165}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737763, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7202610969543457, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2038, "epoch_num": 2549165}}
0: {'global_steps': 3321, 'eval_loss': 1.3061025142669678, 'eval_mlm_accuracy': 0.7202610969543457}
0: 0.720261 > 0.720000, Target MLM Accuracy reached at 3321
0: Training runs 3.697736938794454 mins sustained_training_time 0
0: (1, 3321.0) {'final_loss': 0.0}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2157, "first_epoch_num": 1}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737766, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2160, "epoch_num": 2549165}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737767, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2549165, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2162}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737768, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2165}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737769, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2168, "status": "success"}}
0: :::MLLOG {"namespace": "", "time_ms": 1746130737770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 11742.22163614931, "epoch_num": 2549165}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 2207, "step": [2, 3321]}}
0: {'e2e_time': 231.8179075717926, 'training_sequences_per_second': 12738.60121309133, 'final_loss': 0.0, 'raw_train_time': 221.8642339706421}
++ date +%s
+ echo 'RUNANDTIME_STOP 1746130746'
RUNANDTIME_STOP 1746130746
+ set -e
